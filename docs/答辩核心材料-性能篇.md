# 答辩核心材料：第四部分 - 极致性能与工程化实证

## 1. 核心论点
在面对复杂的多维查询（全文检索 + 标签过滤 + 时间排序）时，单纯依赖数据库索引无法满足高并发下的低延迟需求。本项目引入了 **基于 Redis 的 L3 缓存架构**，实现了 **4.5倍** 的性能提升。

## 2. 实证数据 (Live Demo 截图素材)

我们在本地环境进行了压力测试与缓存验证，结果如下：

> **测试环境**：本地开发机 (Windows), 单实例 Node.js 进程
> **测试工具**：自定义 Node.js 脚本 (`stress-notes.ts`)

| 场景 | 响应时间 (Latency) | 说明 |
| :--- | :--- | :--- |
| **冷启动 (Cold Start)** | **85ms** | 请求穿透至 MongoDB，执行聚合查询 |
| **缓存命中 (Cache Hit)** | **19ms** | 直接从 Redis 读取预计算结果 |
| **性能提升** | **~450% (4.5倍)** | 毫秒级响应，用户体验无感知延迟 |

*(建议在 PPT 中放置 `setup_stress.ps1` 运行输出的截图，重点圈出 `Probe 2 result: latency=19ms`)*

## 3. 关键代码实现 (Code Review 焦点)

### 3.1 精细化缓存键设计 (Cache Key Strategy)
为了防止“缓存雪崩”并确保数据安全（用户隔离），我们设计了包含 `userId` 和 `查询参数哈希` 的复合键。

**文件**：`notes-backend/src/modules/notes/notes.service.ts`

```typescript
// 1. 构建缓存负载 (Payload)
// 包含所有可能影响结果的筛选条件，确保缓存的准确性
const keyPayload = { 
  userId,       // 核心：用户隔离，防止越权访问缓存
  keyword,      // 搜索关键词
  categoryId,   // 分类筛选
  page, size,   // 分页参数
  sortBy,       // 排序规则
  // ...其他过滤条件
};

// 2. 生成唯一指纹 (Fingerprint)
// 使用 SHA1 对参数进行哈希，生成固定长度的 Key，避免 Key 过长影响 Redis 性能
const cacheKey = `notes:list:${userId}:${createHash('sha1').update(JSON.stringify(keyPayload)).digest('hex')}`;
```

### 3.2 读写分离模式 (Read-Aside Pattern)
标准的缓存读写逻辑，保证数据最终一致性（配合 TTL 过期时间）。

```typescript
// 读缓存
try {
  const cached = await this.redis.get(cacheKey);
  if (cached) {
    return JSON.parse(cached); // 命中直接返回，跳过 DB
  }
} catch (e) {
  // 容错设计：Redis 故障不应导致服务不可用，降级查库
  console.error('[CACHE ERROR]', e); 
}

// ... (执行 MongoDB 查询) ...

// 写缓存 (设置 300秒 TTL)
// 权衡：5分钟的数据延迟对于列表页是可接受的，换取了极大的数据库减负
try { 
  await this.redis.set(cacheKey, JSON.stringify(resp), 'EX', 300); 
} catch { /* ignore */ }
```

## 4. 答辩 Q&A 预案

**Q: 为什么压力测试中并发 50 时，P95 延迟达到了 800ms+？**

**A:** 
这是由于 **Node.js 的单线程事件循环模型** 导致的。
1.  **现状**：测试是在本地单进程（Single Instance）下运行的。当 50 个请求同时到达，虽然 Redis 返回很快，但 Node.js 主线程在处理 JSON 序列化/反序列化和 HTTP 协议解析时产生了 **排队效应 (Queuing Delay)**。
2.  **解决方案**：在生产环境中，我们会使用 **PM2 Cluster 模式** 或 **Kubernetes** 进行水平扩展，利用多核 CPU 并行处理请求，从而消除单线程瓶颈。
3.  **重点**：单次请求 19ms 的低延迟证明了架构设计的成功，高并发下的排队是计算资源的物理限制，可以通过加机器/扩容解决。

**Q: 缓存如何处理数据更新？（比如用户修改了笔记）**

**A:**
目前采用了 **TTL (Time-To-Live) 过期策略**（300秒）。
对于列表页，稍微的数据延迟（几分钟）通常是可以接受的。如果需要强一致性，可以在 `update/delete` 操作时引入 **Cache Invalidation (缓存失效)** 机制，即主动删除对应的 `notes:list:${userId}:*` 键（利用 Redis 的 `SCAN` 或维护 Key 集合），但考虑到实现的复杂度和性能开销，当前 TTL 策略是性价比最高的选择。
